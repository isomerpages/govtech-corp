---
layout: post
title: The tricky business of building a code of conduct for AI
permalink: /media/technews/the-tricky-business-of-building-a-code-of-conduct-for-ai/
image: /images/the_tricky_business_of_building_a_code_of_conduct_for_ai_part1.jpg
date: 2019-01-15
description: AI's learning capability poses risks of bias and privacy invasion.
  Mr Rajesh Sreenivasan emphasizes ethics and transparency in AI development.
  ğŸ¤–ğŸ”
variant: tiptap
---
<div class="isomer-image-wrapper">
<img style="width: 100%" height="auto" width="100%" alt="The tricky business of building a code of conduct for AI" src="/images/technews/the-tricky-business-of-building-a-code-of-conduct-for-ai-part1.png">
</div>
<h3>The fact that artificial intelligence (AI) is capable of learning puts it at risk of internalising societyâ€™s prejudices. Left unchecked, AI could encroach on privacy and undermine social values. Ethics and transparency are therefore crucial in the development of AI, said lawyer Mr Rajesh Sreenivasan at the Big Data &amp; AI 2018 conference.</h3>
<p>A certain degree of irony exists in the fact that not one, but two anti-communist
chatbots were spawned in China. Innocuously named â€˜Baby Qâ€™ and â€˜Little
Bingâ€™, the two chatbots were released in 2017 on Tencent QQ, a popular
messenger app in China.</p>
<p>Originally intended for answering general knowledge questionsâ€”say, â€œWhatâ€™s
the weather like today?â€â€”the chatbots drew ire from the ruling Chinese
Communist Party when they began denouncing the Party as â€œcorrupt and incompetentâ€.
Baby Q and Little Bing have since been erased from existence, but their
fleeting encounters with the Chinese public were a revealing case study
of how artificial intelligence (AI) can be influenced by the people it
interacts with.</p>
<p>â€œYou don't have to hack a botâ€”it is constantly learning [through AI].
You just need to understand how it learns and teach it in such a way that
it absorbs what you are telling it. [The bot] then starts to express the
same prejudices as you,â€ said Mr Rajesh Sreenivasan, head of technology,
media and telecommunications at Rajah &amp; Tann Singapore LLP, speaking
at the Big Data &amp; AI 2018 conference on 4 December 2018.</p>
<div class="isomer-image-wrapper">
<img style="width: 100%" height="auto" width="100%" alt="Rajesh Sreenivasan, head of technology, media and telecommunications at Rajah &amp; Tann Singapore LLP, speaking at the Big Data &amp; AI 2018 conference on 4 December 2018" src="/images/technews/the-tricky-business-of-building-a-code-of-conduct-for-ai-part2.png">
</div>
<h3>A focus on ethics and transparency</h3>
<p>Bots have also been â€˜taughtâ€™ by the public to be racist or sexist, added
Mr Sreenivasan; the legal question is: whose fault is this? While there
are no straightforward solutions to issues such as the legal liability
of a racist bot, Mr Sreenivasan noted that society has begun to acknowledge
the need to draw up ethical standards and regulations surrounding the development
and use of AI.</p>
<p>For instance, the Partnership On AI consortium, consisting of AI technology
companies, academics, researchers and civil society, has been established
to formulate best practices on AI technologies.</p>
<p>In Singapore, the Advisory Council on Ethical Use of AI and Data has been
tasked with creating reference governance frameworks and publishing advisory
guidelines for adoption by the industry.</p>
<p>Emphasising the need for a â€œtechnology-neutral and light-touchâ€ approach
to regulating AI, Mr Sreenivasan highlighted two principles that have been
established to guide AI development. Firstly, AI and data analytics (AIDA)-driven
decisions should be held to at least the same ethical standards as human-driven
decisions. This is arguably tricky to assess and abide by, which brings
the second principle into focus: transparency.</p>
<p>â€œTransparency doesn't mean giving away the secret sauceâ€¦ you retain some
of the intellectual property (IP), such as the algorithm, but you must
be transparent on two key areas: what data is used and how the data affects
the [AIâ€™s] decision,â€ he explained.</p>
<h3>Balancing innovation and regulation</h3>
<p>Still, more legal conundrums arise around works created by AI. Here, the
question is whether or not such works constitute IP, and if so, who has
a claim to it. According to Mr Sreenivasan, â€œA compilation of facts and
data may be protected if it constitutes an intellectual creation, by reason
of the selection or arrangement of its contents.â€</p>
<p>Hence, if an AI collects, compiles and processes data about end-users
to present a report about user behaviour, does this constitute an intellectual
creation? â€œThe argument is yes because at that point, the data has been
collated in a unique manner, such that the bot is able to understand it
as a question and respond to it with an answer. Therefore, it is, in fact,
IP,â€ explained Mr Sreenivasan.</p>
<p>And because IP can be created from data, users should have the right to
decide when their data is being collected and how their data is used. This
is where Singaporeâ€™s Personal Data Protection Commission has stepped in
to propose an accountability-based framework for discussing ethical AI
governance and human protection issues in the commercial use of AI.</p>
<p>While such regulations may stifle innovation in AI to some degree, this
cost is something Mr Sreenivasan is willing to accept, he said. â€œIn my
view, it is a price well worth paying because the risk of a completely
unregulated bot-space, or AI-space in the broader sense, is not acceptable,â€
he concluded.</p>